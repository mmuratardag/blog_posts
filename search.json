[
  {
    "objectID": "so_ai_developer_causal.html",
    "href": "so_ai_developer_causal.html",
    "title": "Part 2: Job Satisfaction with 2024 Stack Overflow Developer Survey",
    "section": "",
    "text": "In the previous post, I argued that focusing on individual developers rather than companies is crucial because these professionals, with their diverse backgrounds and immediate influence on AI use cases and policies, directly shape how AI systems are developed and governed. Compared to the governments expected to regulate AI, these developers have a more immediate and practical impact on AI development. Yet, their attitudes and approaches remain largely underexplored.\nHere, I focus on developers’ overall job satisfaction and how it is affected by AI usage, attitudes toward AI, and whether working in the United States or Europe impacts overall job satisfaction.\n\n\nThe AI race has been ongoing for some time. Countries are becoming increasingly aware that leadership in this field could determine their future economic prosperity, geopolitical influence, and national security. A recent report from the UK’s Department for Science, Innovation, & Technology emphasizes prioritizing the training, retention, and attraction of a large and diverse pool of AI talent. The report states that the UK should focus on targeted recruitment to secure its future in the AI field. The UK is not alone; many other countries work on similar strategies.\nThe US and Europe have consistently attracted developers. However, these regions have distinctly different environments for AI development. Consider the following points.\nInnovation vs. Stability: The AI culture in the US is more risk-taking and characterized by a “fail fast” mentality, while Europe tends to adopt a more cautious approach, emphasizing social responsibility and regulations.\nAI-Specific Regulations: While the European approach involves extensive regulation and prioritizes fostering an environment focused on responsible AI, the US regulatory landscape continues to evolve, reflecting shifts from the Trump administration’s largely market-driven stance to the Biden administration’s more proactive emphasis on accountability, oversight, and consumer protection in AI technologies. Let’s see how the second Trump era will impact the AI landscape in the U.S. over the long term.\nAs a result, we can anticipate varying AI regulations regarding ethics, transparency, bias reduction, and data privacy in these areas. These regulations will influence developers’ daily responsibilities and adoption when creating AI systems, and developers can influence how these regulations are implemented in their workplaces.\nThis leads me to ask: do contextual differences affect developers’ overall job satisfaction due to the country’s AI culture?\n\n\nStack Overflow has been surveying its developer community on various topics for over a decade. The 2024 survey includes questions about AI usage and attitudes toward AI, factors contributing to developers’ coding satisfaction, and a self-report of overall job satisfaction. This is a practical starting point.\nAlthough the study’s design is far from a randomized controlled trial, I used working in the US vs. Europe as an experimental treatment because the US and Europe represent naturally occurring distinct environments for AI development, with:\n\nContrasting cultural settings (risk-taking vs. cautious).\nDifferent regulatory approaches (market-driven vs. comprehensive regulation).\n\nI utilized various causal modeling techniques to determine if living in the US or Europe impacts developers’ overall job satisfaction. My methodological approach, involving double ML, causal segmentation model, and Bayesian networks, is deliberately inductive, allowing the different models to uncover distinct insights.\nBefore diving into the results, here is the table that outlines all the variables used in the models.\n\n\n\n\n\n\n\n\nAbbreviations\n\n\nLong Form\n\n\nExplanations\n\n\n\n\n\n\nOutcome: JobSat\n\n\nJob Satisfaction\n\n\nHow satisfied are you in your current professional developer role?\n\n\n\n\nTreatment: TRT_USvEU\n\n\nResiding in the U.S. vs. Europe\n\n\nAll developers who reside in EU countries + the UK are categorized as Europe\n\n\n\n\nSocio-Demographics:\n\n\n\n\n\n\n\n\nMainBranch\n\n\nOption that best describes the developer\n\n\nlearning to code; code primarily as a hobby; used to be a developer by profession but no longer is; not primarily a developer, but writes code sometimes as part of work/studies; developer by profession\n\n\n\n\nAge\n\n\nAge group\n\n\n&lt;18; 18-24; 25-34; 35-44; 45-54; 55-64; 65+; prefer not to say\n\n\n\n\nEmployment\n\n\nActively working or not\n\n\nNot actively working means: not employed, but looking for work; not employed, and not looking for work; student, full-time; student, part-time; retired. Actively working means: employed, full-time; employed, part-time; independent contractor, freelancer, or self-employed\n\n\n\n\nEdLevel\n\n\nEducation Level\n\n\nlow: no university degree; high: bachelor’s and/or master’s degree; higher: professional degree\n\n\n\n\nLearnCode\n\n\nLearned to code formally or not\n\n\nlearned to code at university or not\n\n\n\n\nYearsCode\n\n\nYears of coding in total\n\n\nincluding education\n\n\n\n\nDataScientist\n\n\nData Scientist or not\n\n\nworks as a data scientist/ML specialist or any other developer role\n\n\n\n\nEstimated Scores on AI Usage & Attitudes toward AI:\n\n\n\n\n\n\n\n\nAI_impr_comp_prod_effc\n\n\nAI Improves Productivity & Efficiency in Company\n\n\nhigher scores indicate that the developer believes the adoption of AI by the developer’s company has led to higher productivity and efficiency\n\n\n\n\nAI_complex_confidence\n\n\nConfidence in AI Tool Development for Complex Tasks\n\n\nhigher scores indicate a positive stance on AI adoption, trust in its accuracy, and confidence in AI handling complex tasks\n\n\n\n\nAI_ethics_gov\n\n\nAttitudes in AI Ethics & Governance\n\n\nhigher scores mean higher concerns about AI ethics & governance\n\n\n\n\nAI_use_con_lea_sea\n\n\nAI Usage in Content Generation, Learning & Search\n\n\nhigher scores indicate higher usage\n\n\n\n\nAI_use_production\n\n\nAI Usage in Production\n\n\n\n\nAI_use_doc_test\n\n\nAI Usage in Documenting & Testing\n\n\n\n\nAI_use_proj_plan\n\n\nAI Usage in Project Planning\n\n\n\n\n\n\n\n\nThe overall differences in job satisfaction levels between U.S. and European developers are minor, and the causal machine learning algorithms with double ML1 provide mixed results: only the XGBoost algorithm indicates a significant effect. A causal segmentation model2: shows that the impact is most relevant for highly educated unemployed developers – this segment of developers in Europe report significantly lower levels of job satisfaction.\nThe causal forest algorithm reveals that the most important predictors are Confidence in AI Tool Development for Complex Tasks, Attitudes in AI Ethics & Government, and years of coding.\n\nA basic explainable AI approach to the causal forest highlights the non-linear relationships. Looking at the partial dependence plots, four variables’ complex relationships to the outcome stand out: these variables are thinking that AI Improves Productivity & Efficiency in Company, the Confidence in AI Tool Development for Complex Tasks, Attitudes in AI Ethics & Government, and AI Usage in Content Generation, Learning & Search.\n\nWe also observe that the interaction strengths of these variables influence the reported job satisfaction of developers in the U.S. and Europe.\n\nNote that explainable AI does not always mean interpretable AI. I turn to one of my favorite causal modeling approaches to make these findings interpretable.\n\n\nThis approach has at least three key advantages: we are not restricted to a single outcome variable, we do not have to adhere to specific distributional assumptions, and the inductive approach can be flexible rather than strictly dictated by theory.\nSince the U.S. and Europe represent naturally occurring distinct environments for AI development, and the preliminary models mentioned above hint at nonlinear, complex relationships, I adopted an inductive approach, split the data into European and U.S. samples, and let the model uncover the distinct paths in these environments.\n\n\n\nAlmost none of the demographics are related to the main variables in the U.S. sample. Only years of professional coding have a small positive effect on job satisfaction. What is striking is that this relationship is entirely independent of all other relationships in the U.S. context.\nThe model surfaces two central outcomes in the U.S. context. The first one is the Confidence in AI Tool Development for Complex Tasks, which is negatively influenced by Attitudes in AI Ethics & Governance. Concern about AI ethics and governance leads to lower confidence in AI handling complex tasks in the U.S.\nThe second central outcome is AI Usage in Production. Here, the model reveals a flow in AI usage. AI Usage for Content Generation, Learning & Search leads to higher AI Usage in Documenting & Testing and in Project Planning, which in turn leads to higher AI Usage in Production.\nThe most central predictor in the U.S. is the belief that AI Improves Productivity & Efficiency in Company. While this stance increases AI adoption, it also raises concerns about AI Ethics & Governance, and paradoxically increases Confidence in AI Tool Development for Complex Tasks.\n\n\n\n\nIn contrast to the U.S., seniority seems more involved in Europe. Years of professional coding experience have a small and positive effect on job satisfaction. However, years of professional coding experience negatively affect the belief that AI Improves Productivity & Efficiency in Company, and Confidence in AI Tool Development for Complex Tasks. I can think of at least two reasons why: (1) more experienced developers probably witnessed more projects that overpromised and underdelivered, leading to more cautious views. (2) European companies might have more entrenched legacy systems that are harder to integrate with AI, making productivity gains less apparent to experienced developers.\nWhile seniority indicated by MainBranch has small positive effects on the belief that AI Improves Productivity & Efficiency in Company, and AI Usage in Documenting & Testing, higher age leads to higher Confidence in AI Tool Development for Complex Tasks.\nThe most central outcomes for European developers are Confidence in AI Tool Development for Complex Tasks and AI Usage in Documenting & Testing, simply meaning that the number of predictors leading to these outcomes is pretty high. Europe’s strict regulatory framework may make developers more conscious about documenting and testing their AI systems. European business culture tends to be more risk-averse; Europe’s slower and more cautious approach to AI adoption may result in greater emphasis on documentation and testing being more integral to how developers.\nIn contrast to the U.S., AI Ethics & Governance is an outcome, not a predictor. While the two coefficients are similar in magnitude, there is a noteworthy flip in the cause-and-effect order between the U.S. and Europe. Being highly confident in AI technology reduces concerns about AI regulation and government in Europe.\nThe flow of AI usage in Europe is not that different from the one in the U.S., with content generation, learning, and search leading to other applications; almost all of the links between these AI adoption patterns are a bit weaker for the European developers.\nThe most central predictor in Europe is AI Usage in Content Generation, Learning, & Search, followed by the belief that AI usage increases company productivity & efficiency. In contrast to the flow of AI usage in the U.S., AI Usage in Content Generation, Learning, & Search is linked to AI Ethics & Governance in Europe. Higher AI adoption in content generation, learning, and search raises higher concerns about AI ethics and governance. I guess that the more European developers benefit from this productivity gain (i.e., code completion, automatic content creation, personalizing learning materials, or powering search capabilities), the more they become aware of ethical issues and the need for suitable governance structures.\n\n\n\n\n\nThe findings paint a complex picture of the developer landscape. It’s not just about technology; it’s about people, their values, their experiences.\nLet’s start with job satisfaction. While overall job satisfaction is similar in the U.S. and Europe, the finding that highly educated, unemployed developers in Europe report lower satisfaction is a red flag. European companies might be losing talent due to a mismatch between developer expectations and the current job market. This disparity in job satisfaction among highly educated unemployed developers could signal a need for policies that foster a more dynamic and supportive job market for tech talent in Europe.\nIn Europe, experience breeds caution. Your skepticism can be a valuable asset if you’re an experienced European developer. Senior European developers have more room to use their expertise to guide companies toward more realistic and impactful AI projects.\nThe adoption and use of AI in the US and Europe are similar as depicted by the flow in the path models. However, there is a noticeable difference in confidence and ethics surrounding AI.\nBoth US and European developers likely care about ethics, but the emphasis and framing of ethical concerns appear to differ. The path model with the US developers reflects a more productivity and solution-oriented approach where the abilities can lead to a reduced emphasis on broader ethical and governance issues. The European path reflects a more cautious, regulation-aware approach where only overconfidence in AI handling complex tasks leads to an oversight of AI ethics.\n\nThese findings demonstrate that understanding developer job satisfaction requires looking beyond simple comparisons and delving into the interplay of factors like AI culture, ethical considerations, and individual experiences.\nI may write part 3 as a follow-up blog post with the developer profiles included."
  },
  {
    "objectID": "so_ai_developer_causal.html#being-a-developer-in-the-united-states-vs.-in-europe",
    "href": "so_ai_developer_causal.html#being-a-developer-in-the-united-states-vs.-in-europe",
    "title": "Part 2: Job Satisfaction with 2024 Stack Overflow Developer Survey",
    "section": "",
    "text": "The AI race has been ongoing for some time. Countries are becoming increasingly aware that leadership in this field could determine their future economic prosperity, geopolitical influence, and national security. A recent report from the UK’s Department for Science, Innovation, & Technology emphasizes prioritizing the training, retention, and attraction of a large and diverse pool of AI talent. The report states that the UK should focus on targeted recruitment to secure its future in the AI field. The UK is not alone; many other countries work on similar strategies.\nThe US and Europe have consistently attracted developers. However, these regions have distinctly different environments for AI development. Consider the following points.\nInnovation vs. Stability: The AI culture in the US is more risk-taking and characterized by a “fail fast” mentality, while Europe tends to adopt a more cautious approach, emphasizing social responsibility and regulations.\nAI-Specific Regulations: While the European approach involves extensive regulation and prioritizes fostering an environment focused on responsible AI, the US regulatory landscape continues to evolve, reflecting shifts from the Trump administration’s largely market-driven stance to the Biden administration’s more proactive emphasis on accountability, oversight, and consumer protection in AI technologies. Let’s see how the second Trump era will impact the AI landscape in the U.S. over the long term.\nAs a result, we can anticipate varying AI regulations regarding ethics, transparency, bias reduction, and data privacy in these areas. These regulations will influence developers’ daily responsibilities and adoption when creating AI systems, and developers can influence how these regulations are implemented in their workplaces.\nThis leads me to ask: do contextual differences affect developers’ overall job satisfaction due to the country’s AI culture?\n\n\nStack Overflow has been surveying its developer community on various topics for over a decade. The 2024 survey includes questions about AI usage and attitudes toward AI, factors contributing to developers’ coding satisfaction, and a self-report of overall job satisfaction. This is a practical starting point.\nAlthough the study’s design is far from a randomized controlled trial, I used working in the US vs. Europe as an experimental treatment because the US and Europe represent naturally occurring distinct environments for AI development, with:\n\nContrasting cultural settings (risk-taking vs. cautious).\nDifferent regulatory approaches (market-driven vs. comprehensive regulation).\n\nI utilized various causal modeling techniques to determine if living in the US or Europe impacts developers’ overall job satisfaction. My methodological approach, involving double ML, causal segmentation model, and Bayesian networks, is deliberately inductive, allowing the different models to uncover distinct insights.\nBefore diving into the results, here is the table that outlines all the variables used in the models.\n\n\n\n\n\n\n\n\nAbbreviations\n\n\nLong Form\n\n\nExplanations\n\n\n\n\n\n\nOutcome: JobSat\n\n\nJob Satisfaction\n\n\nHow satisfied are you in your current professional developer role?\n\n\n\n\nTreatment: TRT_USvEU\n\n\nResiding in the U.S. vs. Europe\n\n\nAll developers who reside in EU countries + the UK are categorized as Europe\n\n\n\n\nSocio-Demographics:\n\n\n\n\n\n\n\n\nMainBranch\n\n\nOption that best describes the developer\n\n\nlearning to code; code primarily as a hobby; used to be a developer by profession but no longer is; not primarily a developer, but writes code sometimes as part of work/studies; developer by profession\n\n\n\n\nAge\n\n\nAge group\n\n\n&lt;18; 18-24; 25-34; 35-44; 45-54; 55-64; 65+; prefer not to say\n\n\n\n\nEmployment\n\n\nActively working or not\n\n\nNot actively working means: not employed, but looking for work; not employed, and not looking for work; student, full-time; student, part-time; retired. Actively working means: employed, full-time; employed, part-time; independent contractor, freelancer, or self-employed\n\n\n\n\nEdLevel\n\n\nEducation Level\n\n\nlow: no university degree; high: bachelor’s and/or master’s degree; higher: professional degree\n\n\n\n\nLearnCode\n\n\nLearned to code formally or not\n\n\nlearned to code at university or not\n\n\n\n\nYearsCode\n\n\nYears of coding in total\n\n\nincluding education\n\n\n\n\nDataScientist\n\n\nData Scientist or not\n\n\nworks as a data scientist/ML specialist or any other developer role\n\n\n\n\nEstimated Scores on AI Usage & Attitudes toward AI:\n\n\n\n\n\n\n\n\nAI_impr_comp_prod_effc\n\n\nAI Improves Productivity & Efficiency in Company\n\n\nhigher scores indicate that the developer believes the adoption of AI by the developer’s company has led to higher productivity and efficiency\n\n\n\n\nAI_complex_confidence\n\n\nConfidence in AI Tool Development for Complex Tasks\n\n\nhigher scores indicate a positive stance on AI adoption, trust in its accuracy, and confidence in AI handling complex tasks\n\n\n\n\nAI_ethics_gov\n\n\nAttitudes in AI Ethics & Governance\n\n\nhigher scores mean higher concerns about AI ethics & governance\n\n\n\n\nAI_use_con_lea_sea\n\n\nAI Usage in Content Generation, Learning & Search\n\n\nhigher scores indicate higher usage\n\n\n\n\nAI_use_production\n\n\nAI Usage in Production\n\n\n\n\nAI_use_doc_test\n\n\nAI Usage in Documenting & Testing\n\n\n\n\nAI_use_proj_plan\n\n\nAI Usage in Project Planning"
  },
  {
    "objectID": "so_ai_developer_causal.html#findings",
    "href": "so_ai_developer_causal.html#findings",
    "title": "Part 2: Job Satisfaction with 2024 Stack Overflow Developer Survey",
    "section": "",
    "text": "The overall differences in job satisfaction levels between U.S. and European developers are minor, and the causal machine learning algorithms with double ML1 provide mixed results: only the XGBoost algorithm indicates a significant effect. A causal segmentation model2: shows that the impact is most relevant for highly educated unemployed developers – this segment of developers in Europe report significantly lower levels of job satisfaction.\nThe causal forest algorithm reveals that the most important predictors are Confidence in AI Tool Development for Complex Tasks, Attitudes in AI Ethics & Government, and years of coding.\n\nA basic explainable AI approach to the causal forest highlights the non-linear relationships. Looking at the partial dependence plots, four variables’ complex relationships to the outcome stand out: these variables are thinking that AI Improves Productivity & Efficiency in Company, the Confidence in AI Tool Development for Complex Tasks, Attitudes in AI Ethics & Government, and AI Usage in Content Generation, Learning & Search.\n\nWe also observe that the interaction strengths of these variables influence the reported job satisfaction of developers in the U.S. and Europe.\n\nNote that explainable AI does not always mean interpretable AI. I turn to one of my favorite causal modeling approaches to make these findings interpretable.\n\n\nThis approach has at least three key advantages: we are not restricted to a single outcome variable, we do not have to adhere to specific distributional assumptions, and the inductive approach can be flexible rather than strictly dictated by theory.\nSince the U.S. and Europe represent naturally occurring distinct environments for AI development, and the preliminary models mentioned above hint at nonlinear, complex relationships, I adopted an inductive approach, split the data into European and U.S. samples, and let the model uncover the distinct paths in these environments.\n\n\n\nAlmost none of the demographics are related to the main variables in the U.S. sample. Only years of professional coding have a small positive effect on job satisfaction. What is striking is that this relationship is entirely independent of all other relationships in the U.S. context.\nThe model surfaces two central outcomes in the U.S. context. The first one is the Confidence in AI Tool Development for Complex Tasks, which is negatively influenced by Attitudes in AI Ethics & Governance. Concern about AI ethics and governance leads to lower confidence in AI handling complex tasks in the U.S.\nThe second central outcome is AI Usage in Production. Here, the model reveals a flow in AI usage. AI Usage for Content Generation, Learning & Search leads to higher AI Usage in Documenting & Testing and in Project Planning, which in turn leads to higher AI Usage in Production.\nThe most central predictor in the U.S. is the belief that AI Improves Productivity & Efficiency in Company. While this stance increases AI adoption, it also raises concerns about AI Ethics & Governance, and paradoxically increases Confidence in AI Tool Development for Complex Tasks.\n\n\n\n\nIn contrast to the U.S., seniority seems more involved in Europe. Years of professional coding experience have a small and positive effect on job satisfaction. However, years of professional coding experience negatively affect the belief that AI Improves Productivity & Efficiency in Company, and Confidence in AI Tool Development for Complex Tasks. I can think of at least two reasons why: (1) more experienced developers probably witnessed more projects that overpromised and underdelivered, leading to more cautious views. (2) European companies might have more entrenched legacy systems that are harder to integrate with AI, making productivity gains less apparent to experienced developers.\nWhile seniority indicated by MainBranch has small positive effects on the belief that AI Improves Productivity & Efficiency in Company, and AI Usage in Documenting & Testing, higher age leads to higher Confidence in AI Tool Development for Complex Tasks.\nThe most central outcomes for European developers are Confidence in AI Tool Development for Complex Tasks and AI Usage in Documenting & Testing, simply meaning that the number of predictors leading to these outcomes is pretty high. Europe’s strict regulatory framework may make developers more conscious about documenting and testing their AI systems. European business culture tends to be more risk-averse; Europe’s slower and more cautious approach to AI adoption may result in greater emphasis on documentation and testing being more integral to how developers.\nIn contrast to the U.S., AI Ethics & Governance is an outcome, not a predictor. While the two coefficients are similar in magnitude, there is a noteworthy flip in the cause-and-effect order between the U.S. and Europe. Being highly confident in AI technology reduces concerns about AI regulation and government in Europe.\nThe flow of AI usage in Europe is not that different from the one in the U.S., with content generation, learning, and search leading to other applications; almost all of the links between these AI adoption patterns are a bit weaker for the European developers.\nThe most central predictor in Europe is AI Usage in Content Generation, Learning, & Search, followed by the belief that AI usage increases company productivity & efficiency. In contrast to the flow of AI usage in the U.S., AI Usage in Content Generation, Learning, & Search is linked to AI Ethics & Governance in Europe. Higher AI adoption in content generation, learning, and search raises higher concerns about AI ethics and governance. I guess that the more European developers benefit from this productivity gain (i.e., code completion, automatic content creation, personalizing learning materials, or powering search capabilities), the more they become aware of ethical issues and the need for suitable governance structures."
  },
  {
    "objectID": "so_ai_developer_causal.html#the-key-takeaways",
    "href": "so_ai_developer_causal.html#the-key-takeaways",
    "title": "Part 2: Job Satisfaction with 2024 Stack Overflow Developer Survey",
    "section": "",
    "text": "The findings paint a complex picture of the developer landscape. It’s not just about technology; it’s about people, their values, their experiences.\nLet’s start with job satisfaction. While overall job satisfaction is similar in the U.S. and Europe, the finding that highly educated, unemployed developers in Europe report lower satisfaction is a red flag. European companies might be losing talent due to a mismatch between developer expectations and the current job market. This disparity in job satisfaction among highly educated unemployed developers could signal a need for policies that foster a more dynamic and supportive job market for tech talent in Europe.\nIn Europe, experience breeds caution. Your skepticism can be a valuable asset if you’re an experienced European developer. Senior European developers have more room to use their expertise to guide companies toward more realistic and impactful AI projects.\nThe adoption and use of AI in the US and Europe are similar as depicted by the flow in the path models. However, there is a noticeable difference in confidence and ethics surrounding AI.\nBoth US and European developers likely care about ethics, but the emphasis and framing of ethical concerns appear to differ. The path model with the US developers reflects a more productivity and solution-oriented approach where the abilities can lead to a reduced emphasis on broader ethical and governance issues. The European path reflects a more cautious, regulation-aware approach where only overconfidence in AI handling complex tasks leads to an oversight of AI ethics.\n\nThese findings demonstrate that understanding developer job satisfaction requires looking beyond simple comparisons and delving into the interplay of factors like AI culture, ethical considerations, and individual experiences.\nI may write part 3 as a follow-up blog post with the developer profiles included."
  },
  {
    "objectID": "so_ai_developer_causal.html#footnotes",
    "href": "so_ai_developer_causal.html#footnotes",
    "title": "Part 2: Job Satisfaction with 2024 Stack Overflow Developer Survey",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nHere, I utilized an interactive instrumental model, which in the DoubleML framework incorporates treatment effect heterogeneity through interactions between instruments and covariates. This method estimates local average treatment effects for participants whose treatment status is influenced by the instrumental variable while accounting for complex relationships between the instrument variable, treatment, and outcome. The model provides robust estimates in high-dimensional settings with nonlinear relationships between variables. This is a flexible tool for causal inference when standard instrumental variable assumptions are insufficient. Another advantage here is the flexibility of employing various ML algorithms.↩︎\nNetflix researchers developed a novel methodological framework for identifying subgroups for which treatment effects are heterogeneous in large-scale experiments. The framework uses machine learning to uncover differential treatment impacts across segments in the sample. It integrates causal inference techniques not only for segment discovery but also for evaluating dynamic treatment assignment strategies.↩︎\nThis technique uses probabilistic graphical modeling to represent variables and their conditional relationships as a directed network. It helps uncover complex causal relationships and is flexible enough to account for direct and indirect effects. The model results outline the causal mechanisms by surfacing the different paths between the predictors and the outcomes. I utilized the Tabu search algorithm to deduce the structure of these networks from the data. This optimization technique explores the space of potential network structures through iterative local adjustments. Notably, the algorithm employs a “tabu” list to prevent revisiting previously explored configurations and cycles, thus avoiding entrapment in local optima. Furthermore, I performed bootstrapping with 10000 iterations to evaluate the stability of the network structures. Subsequently, averaged networks were generated with a stringent threshold of 99% to retain only the most robust connections. In the final stage, I parameterized the edges of the estimated network to enable meaningful interpretation.↩︎"
  },
  {
    "objectID": "so_ai_developer_profile.html",
    "href": "so_ai_developer_profile.html",
    "title": "Part 1: Developer Profiles with 2024 Stack Overflow Developer Survey",
    "section": "",
    "text": "When discussing AI, we often focus on the companies involved. However, the diversity in developer attitudes towards AI plays a crucial role in shaping the development and governance of AI systems. Therefore, it is essential to understand the profiles of individual AI developers, as these professionals directly impact how AI systems are developed and governed. Unlike government regulators, tech professionals have immediate influence over AI use cases and company policies. Despite their significant impact on AI systems that affect societies, we have limited knowledge about developer attitudes towards AI.\nThis gap in understanding is particularly significant when considering how developers’ diverse backgrounds influence their approach to AI development and adoption. The annual StackOverflow Developer Survey is a pragmatic start to addressing this gap.\n\n\n\nFor over a decade, Stack Overflow has surveyed its developer community on various topics and technologies. Starting in 2023, the survey began to include questions about AI. The annual Developer Survey for 20241 has expanded its focus on AI with many items on AI usage and attitudes towards AI.\n\n\n\nUsing the survey items from 2024 on AI, I estimated profiles from two broad territories, namely, developers from the US & Europe. In this subsample, 31% of the participants reported living in the United States. Among the European developers, 14% are from Germany, 9% from the United Kingdom, 6% from France, and the remaining 40% are from various other European countries. Almost 1/3 of this sample consists of full-stack developers, while back-end developers (16 %) hold the second most common role. These two are followed by students (8 %) and front-end developers (5 %). The percentages of all remaining developer roles range from 0.01% to 5%.\n\n\n\n\n\nAn exploratory graph analysis of 47 items reveals seven dimensions (read as latent variables). The figure below illustrates the items under analysis, along with the estimated dimensions and their corresponding labels. The nodes represent the survey items, while the edges indicate the associations between these items. Node colors reflect the estimated underlying latent constructs. In other words, the identified latent constructs (dimensions) are a good and accurate psychometric summary of the 47 items on AI.\n\nThese latent constructs tap into various aspects of AI usage and attitudes toward AI. For example, AI Improves Productivity & Efficiency in Company reflects the belief that the adoption of AI by the developer’s company has led to higher productivity and efficiency. AI Tool Development Confidence in Complex Tasks measures the stance on AI adoption, trust in its accuracy, and confidence in AI handling complex tasks. All the other labels should be self-explanatory.\n\n\n\nI utilized all these seven latent variables along with an additional latent variable that measures overall job satisfaction to estimate five distinct developer profiles. Here is what I discovered.\n\nJob satisfaction within this sample is generally low.\nAI usage in production is minimal across all profiles.\n\nSee the visual below to form a picture in your head before I list a few brief details about each profile.\n\n\nThe profile ratios in the sample are quite similar across territories.\n\n\n\n\nThis profile is the most common, representing 47% of the sample. I mentioned that the sample is dominated by full-stack, back-end, front-end developers & students. Well… after these roles, the most common professions are developers of “Mobile Apps”, “Desktop or Enterprise Apps”, “Embedded Applications or Devices”, and “Academic Researcher”. This profile is an optimizer. The AI adoption and general orientation towards AI are balanced; there is 0 or almost 0 usage of AI in production and project planning.\n\n\n\n12 % of the sample is represented by this profile; I am sure you have come across the type. There is an unwavering faith in AI’s ability to handle complexity. However, in contrast, scores on everything else are very, very low. For this profile, three roles stand out besides the sample’s most frequent developer types: “Academic Researcher,” “Research & Development Role,” and “Data Engineer”.\n\n\n\nThe percentage of this profile is another 12 %. This profile is relatively conservative in adopting broad AI solutions. We also observe moderate levels of confidence in AI handling complex tasks and moderate concerns about AI ethics and governance. My guess is that the general orientation is shaped by the opposing narratives around AI: AI the savior vs. AI the destructor! So, what are the most frequent roles besides the usual suspects of the sample, you ask? “Engineering Manager”, “DevOps Specialist”, “Academic Researcher” and “Data Engineer”.\n\n\n\n14 % of the sample is classified as this profile that embraces AI across multiple domains—from content generation, learning, and search to documenting and testing. The profile is characterized by high scores on AI improves company productivity & efficiency and AI usage in content generation, learning & search. Compared to other profiles, this profile has the highest scores in AI usage for documenting & testing and in project planning with AI. “Data Scientist or Machine Learning Specialist” is the most frequent role following the sample’s most frequent developer types.\n\n\n\n17% of the sample is disengaged from anything related to AI, with minimal scores on every dimension. The percentages of developer types are similar to the first profile: the optimizer.\n\n\n\n\nIf you want to reverse the order and see the developer roles by profiles, the chart below is all yours to stare at.\n\n\n\n\nHmm.. what’s that?.. You are intrigued and want to know which of these profiles you might be?.. Well.. lucky you… there is an app for that! Go to the following link, respond to the 64 items, and learn your profile. It takes 5-10 minutes.\nhttps://stack-overflow-developer-profiler-2024.streamlit.app/\nIn Part 2 of this blog post, I discuss causality related to job satisfaction. Make sure to read that as well."
  },
  {
    "objectID": "so_ai_developer_profile.html#why-it-is-a-good-idea-to-focus-on-the-individuals-instead-of-companies",
    "href": "so_ai_developer_profile.html#why-it-is-a-good-idea-to-focus-on-the-individuals-instead-of-companies",
    "title": "Part 1: Developer Profiles with 2024 Stack Overflow Developer Survey",
    "section": "",
    "text": "When discussing AI, we often focus on the companies involved. However, the diversity in developer attitudes towards AI plays a crucial role in shaping the development and governance of AI systems. Therefore, it is essential to understand the profiles of individual AI developers, as these professionals directly impact how AI systems are developed and governed. Unlike government regulators, tech professionals have immediate influence over AI use cases and company policies. Despite their significant impact on AI systems that affect societies, we have limited knowledge about developer attitudes towards AI.\nThis gap in understanding is particularly significant when considering how developers’ diverse backgrounds influence their approach to AI development and adoption. The annual StackOverflow Developer Survey is a pragmatic start to addressing this gap."
  },
  {
    "objectID": "so_ai_developer_profile.html#the-annual-stack-overflow-developer-survey",
    "href": "so_ai_developer_profile.html#the-annual-stack-overflow-developer-survey",
    "title": "Part 1: Developer Profiles with 2024 Stack Overflow Developer Survey",
    "section": "",
    "text": "For over a decade, Stack Overflow has surveyed its developer community on various topics and technologies. Starting in 2023, the survey began to include questions about AI. The annual Developer Survey for 20241 has expanded its focus on AI with many items on AI usage and attitudes towards AI."
  },
  {
    "objectID": "so_ai_developer_profile.html#the-sample",
    "href": "so_ai_developer_profile.html#the-sample",
    "title": "Part 1: Developer Profiles with 2024 Stack Overflow Developer Survey",
    "section": "",
    "text": "Using the survey items from 2024 on AI, I estimated profiles from two broad territories, namely, developers from the US & Europe. In this subsample, 31% of the participants reported living in the United States. Among the European developers, 14% are from Germany, 9% from the United Kingdom, 6% from France, and the remaining 40% are from various other European countries. Almost 1/3 of this sample consists of full-stack developers, while back-end developers (16 %) hold the second most common role. These two are followed by students (8 %) and front-end developers (5 %). The percentages of all remaining developer roles range from 0.01% to 5%."
  },
  {
    "objectID": "so_ai_developer_profile.html#analyses",
    "href": "so_ai_developer_profile.html#analyses",
    "title": "Part 1: Developer Profiles with 2024 Stack Overflow Developer Survey",
    "section": "",
    "text": "An exploratory graph analysis of 47 items reveals seven dimensions (read as latent variables). The figure below illustrates the items under analysis, along with the estimated dimensions and their corresponding labels. The nodes represent the survey items, while the edges indicate the associations between these items. Node colors reflect the estimated underlying latent constructs. In other words, the identified latent constructs (dimensions) are a good and accurate psychometric summary of the 47 items on AI.\n\nThese latent constructs tap into various aspects of AI usage and attitudes toward AI. For example, AI Improves Productivity & Efficiency in Company reflects the belief that the adoption of AI by the developer’s company has led to higher productivity and efficiency. AI Tool Development Confidence in Complex Tasks measures the stance on AI adoption, trust in its accuracy, and confidence in AI handling complex tasks. All the other labels should be self-explanatory.\n\n\n\nI utilized all these seven latent variables along with an additional latent variable that measures overall job satisfaction to estimate five distinct developer profiles. Here is what I discovered.\n\nJob satisfaction within this sample is generally low.\nAI usage in production is minimal across all profiles.\n\nSee the visual below to form a picture in your head before I list a few brief details about each profile.\n\n\nThe profile ratios in the sample are quite similar across territories.\n\n\n\n\nThis profile is the most common, representing 47% of the sample. I mentioned that the sample is dominated by full-stack, back-end, front-end developers & students. Well… after these roles, the most common professions are developers of “Mobile Apps”, “Desktop or Enterprise Apps”, “Embedded Applications or Devices”, and “Academic Researcher”. This profile is an optimizer. The AI adoption and general orientation towards AI are balanced; there is 0 or almost 0 usage of AI in production and project planning.\n\n\n\n12 % of the sample is represented by this profile; I am sure you have come across the type. There is an unwavering faith in AI’s ability to handle complexity. However, in contrast, scores on everything else are very, very low. For this profile, three roles stand out besides the sample’s most frequent developer types: “Academic Researcher,” “Research & Development Role,” and “Data Engineer”.\n\n\n\nThe percentage of this profile is another 12 %. This profile is relatively conservative in adopting broad AI solutions. We also observe moderate levels of confidence in AI handling complex tasks and moderate concerns about AI ethics and governance. My guess is that the general orientation is shaped by the opposing narratives around AI: AI the savior vs. AI the destructor! So, what are the most frequent roles besides the usual suspects of the sample, you ask? “Engineering Manager”, “DevOps Specialist”, “Academic Researcher” and “Data Engineer”.\n\n\n\n14 % of the sample is classified as this profile that embraces AI across multiple domains—from content generation, learning, and search to documenting and testing. The profile is characterized by high scores on AI improves company productivity & efficiency and AI usage in content generation, learning & search. Compared to other profiles, this profile has the highest scores in AI usage for documenting & testing and in project planning with AI. “Data Scientist or Machine Learning Specialist” is the most frequent role following the sample’s most frequent developer types.\n\n\n\n17% of the sample is disengaged from anything related to AI, with minimal scores on every dimension. The percentages of developer types are similar to the first profile: the optimizer.\n\n\n\n\nIf you want to reverse the order and see the developer roles by profiles, the chart below is all yours to stare at.\n\n\n\n\nHmm.. what’s that?.. You are intrigued and want to know which of these profiles you might be?.. Well.. lucky you… there is an app for that! Go to the following link, respond to the 64 items, and learn your profile. It takes 5-10 minutes.\nhttps://stack-overflow-developer-profiler-2024.streamlit.app/\nIn Part 2 of this blog post, I discuss causality related to job satisfaction. Make sure to read that as well."
  },
  {
    "objectID": "so_ai_developer_profile.html#footnotes",
    "href": "so_ai_developer_profile.html#footnotes",
    "title": "Part 1: Developer Profiles with 2024 Stack Overflow Developer Survey",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nStack Overflow has long been the primary resource for developers until the generative AI boom. You have probably seen the news about the drastic drop in the site’s traffic with the introduction of chatbots like ChatGPT. In the spring of 2024, Stack Overflow announced a partnership with OpenAI in which Stack Overflow will provide vetted technical content through OverflowAPI to enhance OpenAI’s models, while OpenAI will integrate Stack Overflow’s validated knowledge directly into ChatGPT with proper attribution. The deal has caused controversy among the Stack Overflow community: a considerable number of contributors expressed anger and protest over using their contributions to train AI models. While the annual Developer Survey from 2024 is likely to reflect some of this drama, the data is as valuable as always and includes quite a few items on AI usage and attitudes toward AI.↩︎"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Posts",
    "section": "",
    "text": "Most recent posts\n22/01/2025: Part 2: Job Satisfaction with 2024 Stack Overflow Developer Survey\n26/12/2024: Part 1: Developer Profiles with 2024 Stack Overflow Developer Survey\n\n\n\n\n15/03/2023: Sharing Knowledge, Not Hoarding It: Tackling Organizational Silos – Survey results from Stack Overflow 2022\n15/06/2022: What do political psychologists study?\n23/04/2022: Coauthor network analysis of political psychologists\n09/01/2022: What was the highlight of my Ph.D. work?\n29/07/2021: Psychological profiles, socio-demographics and political orientation, and the way many sociologists, political scientists and psychologists think of them\n08/03/2021: Visualizing vDEM democracy scores using plotly…\n26/04/2020: An informal benchmarking within psychometrics: attitude network approach vs. the general SEM framework using German national identity as an example\n02/12/2019: Ultra-short version of Collective Narcissism Scale for the Prejudice Lab at Goldsmiths, University of London. Pdf version here; HTML version here.\n09/06/2019: Juxtaposing psychometrics, topic modeling, and social network analysis to model competing nationalist discourses\n16/04/2019: semtree vs. network tree"
  }
]